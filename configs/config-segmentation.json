{
    "path_to_material_class_file": "categories/materials-minc.csv",
    "path_to_data_set_information_file": "data/512/data-set-information.json",
    "path_to_labeled_photos": "data/512/labeled/photos.tar.gz",
    "path_to_labeled_masks": "data/512/labeled/masks.tar.gz",
    "path_to_unlabeled_photos": "data/512/unlabeled.tar.gz",

    "log_file_path": "model-data/{model_folder}/logs/log.txt",
    "log_to_stdout": true,

    "keras_tensorboard_log_path": "model-data/{model_folder}/logs/tensorboard/",
    "keras_model_checkpoint_file_path": "model-data/{model_folder}/checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5",
    "keras_csv_log_file_path": "model-data/{model_folder}/logs/per-epoch-data.csv",
    "optimizer_checkpoint_file_path": "model-data/{model_folder}/checkpoints/optimizer/optimizer-checkpoint.json",

    "keras_model_checkpoint": {
      "checkpoint_file_path": "model-data/{model_folder}/checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5",
      "monitor": "val_loss",
      "verbose": 1,
      "save_best_only": false,
      "save_weights_only": false,
      "mode": "auto",
      "period": 1
    },

    "loss_function": "dummy",

    "num_epochs": 100,
    "input_shape": [null, null, 3],
    "crop_shape": [[384, 384], [256, 256], [128, 128]],
    "resize_shape": null,
    "div2_constraint": 4,
    "num_crop_reattempts": 5,

    "num_labeled_per_batch": 10,
    "num_unlabeled_per_batch": 10,
    "validation_num_labeled_per_batch": 5,
    "validation_crop_shape": null,
    "validation_resize_shape": [512, 512],

    "num_color_channels": 3,
    "random_seed": 14874,

    "optimizer": {
      "name": "adam",
      "learning_rate": 5e-4,
      "momentum": 0.9,
      "decay": 2e-4
    },

    "mean_teacher_params": {
      "teacher_model_checkpoint_file_path": "model-data/{model_folder}/checkpoints/teacher/teacher_weights.{epoch:02d}-{val_loss:.2f}.hdf5",
      "ema_smoothing_coefficient_function": "lambda x: 0.99 if x < 40000 else 0.999",
      "consistency_cost_coefficient_function": "lambda x: 1.0 * min( np.exp( min(-5.0 * (1.0 - ((float(x)/40000.0)**2)), 1.0) ), 1.0 )"
    },

    "superpixel_params": {
      "unlabeled_cost_coefficient_function": "lambda x: 0.0 if x < 10000 else 5.0 * min(np.exp(-5.0 * (1.0 - ((float(x-10000)/40000.0)**2))), 1.0)",
      "label_generation_function_name": "felzenszwalb"
    },

    "use_data_augmentation": true,
    "use_material_samples": true,

    "data_augmentation_params": {
      "augmentation_probability_function": "lambda x: 0.8 * min( np.exp( min(-5.0 * (1.0 - ((float(x)/12000.0)**2)), 1.0) ), 1.0 )",
      "rotation_range": 40.0,
      "zoom_range": 0.25,
      "width_shift_range": 0.05,
      "height_shift_range": 0.05,
      "channel_shift_range": 0.05,
      "horizontal_flip": true,
      "vertical_flip": false,
      "gaussian_noise_stddev_function": "lambda x: 0.05 * min( np.exp( min(-5.0 * (1.0 - ((float(x)/12000.0)**2)), 1.0) ), 1.0 )",
      "gamma_adjust_range": 0.5
    },

    "reduce_lr_on_plateau": {
      "factor": 0.1,
      "verbose": 1,
      "patience": 2,
      "epsilon": 0.0001,
      "cooldown": 2,
      "min_lr": 0,
      "monitor": "val_loss"
    },

    "_early_stopping": {
      "monitor": "val_loss",
      "min_delta": 0,
      "patience": 2,
      "verbose": 0,
      "mode": "auto"
    },

    "transfer_weights": true,

    "transfer_weights_options": {
      "transfer_model_name": "enet-naive-upsampling-encoder-only",
      "transfer_model_input_shape": [362, 362, 3],
      "transfer_model_num_classes": 24,
      "transfer_model_weights_file_path": "model-data/enet-naive-upsampling-encoder-only/supervised-mt/checkpoints/teacher/teacher_weights.13-0.53.hdf5",
      "from_layer_index": 0,
      "to_layer_index": -3,
      "freeze_from_layer_index": 0,
      "freeze_to_layer_index": -3
    },

    "stepwise_learning_rate_scheduler": {
      "lr_schedule": "lambda x: 5e-4 * min( np.exp( min(-5.0 * (1.0 - ((float(x)/40000.0)**2)), 1.0) ), 1.0 )",
      "b2_schedule": "lambda x: 0.99 if x < 40000 else 0.999",
      "last_scheduled_step": 40000,
      "verbose": false
    },

    "image_data_format": "channels_last",
    "continue_from_last_checkpoint": false,
    "use_class_weights": true,
    "override_class_weights": [0.0, 1.0, 0.95233443019187014, 1.0084894598124294, 1.0876336820859942, 0.93513416972375907, 1.3562841644539163, 0.88087027961984254, 0.72744505982135144, 1.1964130410283282, 0.98093916451035346, 1.199377305308204, 1.0086550427731433, 1.0997899973865224, 0.66508626724156616, 1.0516009875177081, 0.86601989283840231, 0.91591412305333431, 1.1624688349949956, 1.3514328500987325, 0.98490163629706184, 0.96256977621705386, 0.90765780461628853, 1.0521964621543587],
    "_enet_bbox_override_class_weights": [0.0, 2.1215443921406503, 2.0434101501187212, 2.1354230608724842, 2.2642844585771895, 2.0151257168300942, 2.6951626632184746, 1.9255701379439607, 1.6694686474110134, 2.4399220507866293, 2.0903426536404721, 2.4446852835443917, 2.1356936471944441, 2.2839953284411498, 1.563996479598619, 2.2057325023413741, 1.9009734053678011, 1.9834622878258954, 2.3852921532375384, 2.6874657308724039, 2.0968337297477362, 2.0602185731141467, 1.9698417391304757, 2.2067016866776314],
    "save_values_on_early_exit": true
}